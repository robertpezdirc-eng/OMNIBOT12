version: "3.9"

networks:
  omni-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

services:
  mongo:
    image: mongo:7
    container_name: omni-mongo-prod
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USERNAME:-omni}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: omni
    ports:
      - "127.0.0.1:27017:27017"  # Bind only to localhost
    volumes:
      - mongo-data:/data/db
      - ./mongo-init:/docker-entrypoint-initdb.d:ro
      - ./backups:/backups
    networks:
      omni-network:
        ipv4_address: 172.20.0.10
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  server:
    build:
      context: .
      dockerfile: Dockerfile-server
      args:
        NODE_ENV: production
    container_name: omni-server-prod
    restart: unless-stopped
    environment:
      MONGO_URI: mongodb://${MONGO_USERNAME:-omni}:${MONGO_PASSWORD}@mongo:27017/omni?authSource=admin
      JWT_SECRET: ${JWT_SECRET}
      PORT: 3000
      NODE_ENV: production
      SSL_CERT_PATH: /app/certs/fullchain.pem
      SSL_KEY_PATH: /app/certs/privkey.pem
      RATE_LIMIT_WINDOW: 900000  # 15 minutes
      RATE_LIMIT_MAX: 100
      LOG_LEVEL: info
    ports:
      - "127.0.0.1:3000:3000"  # Bind only to localhost
    depends_on:
      mongo:
        condition: service_healthy
    volumes:
      - ./certs:/app/certs:ro
      - server-logs:/app/logs
      - ./backups:/app/backups
    networks:
      omni-network:
        ipv4_address: 172.20.0.20
    healthcheck:
      test: ["CMD", "curl", "-k", "-f", "https://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  admin:
    build:
      context: .
      dockerfile: Dockerfile-admin
      args:
        NODE_ENV: production
    container_name: omni-admin-prod
    restart: unless-stopped
    environment:
      SERVER_URL: https://server:3000
      PORT: 4000
      NODE_ENV: production
      RATE_LIMIT_WINDOW: 900000
      RATE_LIMIT_MAX: 50
    ports:
      - "127.0.0.1:4000:4000"  # Bind only to localhost
    depends_on:
      server:
        condition: service_healthy
    volumes:
      - admin-logs:/app/logs
    networks:
      omni-network:
        ipv4_address: 172.20.0.30
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  client:
    build:
      context: .
      dockerfile: Dockerfile-client
      args:
        NODE_ENV: production
    container_name: omni-client-prod
    restart: unless-stopped
    environment:
      SERVER_URL: https://server:3000
      CLIENT_PORT: 5000
      NODE_ENV: production
    ports:
      - "127.0.0.1:5000:5000"  # Bind only to localhost
    depends_on:
      server:
        condition: service_healthy
    volumes:
      - client-logs:/app/logs
    networks:
      omni-network:
        ipv4_address: 172.20.0.40
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  nginx:
    image: nginx:alpine
    container_name: omni-nginx-prod
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./certs:/etc/nginx/certs:ro
      - nginx-logs:/var/log/nginx
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      - server
      - admin
      - client
    networks:
      omni-network:
        ipv4_address: 172.20.0.50
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'

  # Redis for session storage and caching
  redis:
    image: redis:7-alpine
    container_name: omni-redis-prod
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - redis-data:/data
    networks:
      omni-network:
        ipv4_address: 172.20.0.60
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'

  # Monitoring with Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: omni-prometheus
    restart: unless-stopped
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      omni-network:
        ipv4_address: 172.20.0.70
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

volumes:
  mongo-data:
    driver: local
  server-logs:
    driver: local
  admin-logs:
    driver: local
  client-logs:
    driver: local
  nginx-logs:
    driver: local
  redis-data:
    driver: local
  prometheus-data:
    driver: local